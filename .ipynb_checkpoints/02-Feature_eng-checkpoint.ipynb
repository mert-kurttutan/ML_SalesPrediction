{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering of Daily Sales Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from utils import downcast_dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we define downcast function so that pandas dataframes allocate less memory. This is very important given the size of data and features to be produced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 600)\n",
    "pd.set_option('display.max_columns', 50)\n",
    "\n",
    "\n",
    "def name_correction(x):\n",
    "    x = x.lower() # all letters lower case\n",
    "    x = x.partition('[')[0] # partition by square brackets\n",
    "    x = x.partition('(')[0] # partition by curly brackets\n",
    "    x = re.sub('[^A-Za-z0-9А-Яа-я]+', ' ', x) # remove special characters\n",
    "    x = x.replace('  ', ' ') # replace double spaces with single spaces\n",
    "    x = x.strip() # remove leading and trailing white space\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the data\n",
    "df_items = pd.read_csv('data/items.csv')\n",
    "df_categories = pd.read_csv('data/item_categories.csv')\n",
    "df_shops = pd.read_csv('data/shops.csv')\n",
    "df_sales = pd.read_csv('data/sales_train.csv')\n",
    "df_sales_test = pd.read_csv('data/test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing for Auxiliary Tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we extract features from items, shops and categories table. Since I dont know Russian, I took this from <a href=\"https://www.kaggle.com/code/gordotron85/future-sales-xgboost-top-3/notebook\"> public notebook </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13544/2699662849.py:5: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "  df_items[\"name1\"], df_items[\"name2\"] = df_items.item_name.str.split(\"[\", 1).str\n",
      "/tmp/ipykernel_13544/2699662849.py:6: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "  df_items[\"name1\"], df_items[\"name3\"] = df_items.item_name.str.split(\"(\", 1).str\n",
      "/tmp/ipykernel_13544/2699662849.py:9: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df_items[\"name2\"] = df_items.name2.str.replace('[^A-Za-z0-9А-Яа-я]+', \" \").str.lower()\n",
      "/tmp/ipykernel_13544/2699662849.py:10: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df_items[\"name3\"] = df_items.name3.str.replace('[^A-Za-z0-9А-Яа-я]+', \" \").str.lower()\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "#Items treating\n",
    "# split item names by first bracket\n",
    "df_items[\"name1\"], df_items[\"name2\"] = df_items.item_name.str.split(\"[\", 1).str\n",
    "df_items[\"name1\"], df_items[\"name3\"] = df_items.item_name.str.split(\"(\", 1).str\n",
    "\n",
    "# replace special characters and turn to lower case\n",
    "df_items[\"name2\"] = df_items.name2.str.replace('[^A-Za-z0-9А-Яа-я]+', \" \").str.lower()\n",
    "df_items[\"name3\"] = df_items.name3.str.replace('[^A-Za-z0-9А-Яа-я]+', \" \").str.lower()\n",
    "\n",
    "# fill nulls with '0'\n",
    "df_items = df_items.fillna('0')\n",
    "\n",
    "df_items[\"item_name\"] = df_items[\"item_name\"].apply(lambda x: name_correction(x))\n",
    "\n",
    "# return all characters except the last if name 2 is not \"0\" - the closing bracket\n",
    "df_items.name2 = df_items.name2.apply( lambda x: x[:-1] if x !=\"0\" else \"0\")\n",
    "\n",
    "df_items[\"type\"] = df_items.name2.apply(lambda x: x[0:8] if x.split(\" \")[0] == \"xbox\" else x.split(\" \")[0] )\n",
    "df_items.loc[(df_items.type == \"x360\") | (df_items.type == \"xbox360\") | (df_items.type == \"xbox 360\") ,\"type\"] = \"xbox 360\"\n",
    "df_items.loc[ df_items.type == \"\", \"type\"] = \"mac\"\n",
    "df_items.type = df_items.type.apply( lambda x: x.replace(\" \", \"\") )\n",
    "df_items.loc[ (df_items.type == 'pc' )| (df_items.type == 'pс') | (df_items.type == \"pc\"), \"type\" ] = \"pc\"\n",
    "df_items.loc[ df_items.type == 'рs3' , \"type\"] = \"ps3\"\n",
    "\n",
    "group_sum = df_items.groupby([\"type\"]).agg({\"item_id\": \"count\"})\n",
    "group_sum = group_sum.reset_index()\n",
    "drop_cols = []\n",
    "for cat in group_sum.type.unique():\n",
    "    if group_sum.loc[(group_sum.type == cat), \"item_id\"].values[0] <40:\n",
    "        drop_cols.append(cat)\n",
    "df_items.name2 = df_items.name2.apply( lambda x: \"other\" if (x in drop_cols) else x )\n",
    "df_items = df_items.drop([\"type\"], axis = 1)\n",
    "\n",
    "df_items.name2 = LabelEncoder().fit_transform(df_items.name2)\n",
    "df_items.name3 = LabelEncoder().fit_transform(df_items.name3)\n",
    "\n",
    "df_items.drop([\"item_name\", \"name1\"],axis = 1, inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Shop treating\n",
    "df_shops.loc[df_shops.shop_name == 'Сергиев Посад ТЦ \"7Я\"', 'shop_name'] = 'СергиевПосад ТЦ \"7Я\"'\n",
    "df_shops['city'] = df_shops['shop_name'].str.split(' ').map(lambda x: x[0])\n",
    "df_shops.loc[df_shops.city == '!Якутск', 'city'] = 'Якутск'\n",
    "df_shops = df_shops[['shop_id','city']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Categories treating\n",
    "df_categories['split'] = df_categories['item_category_name'].str.split('-')\n",
    "df_categories['type'] = df_categories['split'].map(lambda x: x[0].strip())\n",
    "# if subtype is nan then type\n",
    "df_categories['subtype'] = df_categories['split'].map(lambda x: x[1].strip() if len(x) > 1 else x[0].strip())\n",
    "df_categories = df_categories[['item_category_id','type', 'subtype']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tables for Training and Test Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets deal with outliers based on the analysis done EDA notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_sales = df_sales[df_sales.item_price<100000]\n",
    "df_sales = df_sales[df_sales.item_cnt_day<1001]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Якутск Орджоникидзе, 56\n",
    "df_sales.loc[df_sales.shop_id == 0, 'shop_id'] = 57\n",
    "df_sales_test.loc[df_sales_test.shop_id == 0, 'shop_id'] = 57\n",
    "# Якутск ТЦ \"Центральный\"\n",
    "df_sales.loc[df_sales.shop_id == 1, 'shop_id'] = 58\n",
    "df_sales_test.loc[df_sales_test.shop_id == 1, 'shop_id'] = 58\n",
    "# Жуковский ул. Чкалова 39м²\n",
    "df_sales.loc[df_sales.shop_id == 10, 'shop_id'] = 11\n",
    "df_sales_test.loc[df_sales_test.shop_id == 10, 'shop_id'] = 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_sales_test['date_block_num'] = 34\n",
    "df_sales_test['item_cnt_day'] = np.nan\n",
    "df_sales_test['item_price'] = np.nan\n",
    "df_sales_test['date'] = '01.11.2015'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, add the test data to the training data. This will make the analysis very convenient since due to methods provided by pandas package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_sales = pd.concat([df_sales, df_sales_test[['date', 'date_block_num', 'shop_id', 'item_id', 'item_price', 'item_cnt_day']]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we produce a grid object which contains many combination of shop and item id for a given month. In particular, it is formed by cross product of existing shop and existing item_ids for a given month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "# Create \"grid\" with columns\n",
    "index_cols = ['date_block_num', 'shop_id', 'item_id']\n",
    "\n",
    "# For every month we create a grid from all shops/items combinations from that month\n",
    "grid = [] \n",
    "for block_num in df_sales['date_block_num'].unique():\n",
    "    if block_num != 34:\n",
    "        cur_shops = df_sales.loc[df_sales['date_block_num'] == block_num, 'shop_id'].unique()\n",
    "        cur_items = df_sales.loc[df_sales['date_block_num'] == block_num, 'item_id'].unique()\n",
    "        grid.append(np.array(list(product(*[[block_num], cur_shops, cur_items])),dtype='int32'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_block_num</th>\n",
       "      <th>shop_id</th>\n",
       "      <th>item_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>114910</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117150</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120623</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118316</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114602</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date_block_num  shop_id  item_id\n",
       "114910               0        2       19\n",
       "117150               0        2       27\n",
       "120623               0        2       28\n",
       "118316               0        2       29\n",
       "114602               0        2       32"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Turn the grid into a dataframe\n",
    "grid = pd.DataFrame(np.vstack(grid), columns = index_cols,dtype=np.int32)\n",
    "grid.sort_values( index_cols, inplace = True )\n",
    "grid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "grid = pd.concat([grid, df_sales_test[['date_block_num', 'shop_id', 'item_id']]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Groupby data to get (shop, item, month) tuples\n",
    "agg_columns = {'item_cnt_day':'sum'}\n",
    "agg_df = df_sales.groupby(index_cols,as_index=False).agg(agg_columns)\n",
    "agg_df.rename(columns={'item_cnt_day':'target'}, inplace=True)\n",
    "\n",
    "# The last month is test data, target is not defined\n",
    "agg_df.loc[agg_df.date_block_num==34, 'target'] = np.nan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Join it to the grid\n",
    "data_sales = pd.merge(grid, agg_df, how='left', on=index_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Before the test month, if there is no match, it indicates no sales, zero sale\n",
    "data_sales.loc[(data_sales.date_block_num != 34), 'target'] = data_sales.loc[(data_sales.date_block_num != 34), 'target'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Merging everything\n",
    "data_sales = pd.merge(data_sales, df_items, on = 'item_id', how='left')\n",
    "data_sales = pd.merge(data_sales, df_shops, on = 'shop_id', how='left')\n",
    "data_sales = pd.merge(data_sales, df_categories, on = 'item_category_id', how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Label encoding of string data\n",
    "city_encoder = LabelEncoder().fit(data_sales['city'])\n",
    "subtype_encoder = LabelEncoder().fit(data_sales['subtype'])\n",
    "type_encoder = LabelEncoder().fit(data_sales['type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Label encoding\n",
    "data_sales['city'] = city_encoder.transform(data_sales['city'])\n",
    "data_sales['subtype'] = subtype_encoder.transform(data_sales['subtype'])\n",
    "data_sales['type'] = type_encoder.transform(data_sales['type'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, clip the data into range $(0,20)$ since this is done for the test data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_sales.target = data_sales.target.clip(0,20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lagged Features\n",
    "\n",
    "Now, we added lagged features from the past. For instance, we take the prices from the last a few month and one year before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def lag_feature(df, lags, col):\n",
    "    '''\n",
    "    Added lagged features to column col of dataframe df.\n",
    "    Lagging is determined by values in lags\n",
    "    '''\n",
    "    for i in lags:\n",
    "        \n",
    "        shifted = df[['date_block_num','shop_id','item_id',col]].copy()\n",
    "        shifted.columns = ['date_block_num','shop_id','item_id', col+'_lag_'+str(i)]\n",
    "        \n",
    "        # Time shift = lagging\n",
    "        shifted['date_block_num'] += i\n",
    "        df = pd.merge(df, shifted, on=['date_block_num','shop_id','item_id'], how='left')\n",
    "        del(shifted)\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "del df_items, df_categories, df_shops, df_sales_test\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Lagging targets\n",
    "lags = [1, 2, 3, 6, 12]\n",
    "group_cols = ['shop_id', 'item_id']\n",
    "shift_cols = 'target'\n",
    "order_col = 'date_block_num' \n",
    "\n",
    "data_sales = lag_feature(data_sales, lags,shift_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Lagging targets mean month\n",
    "agg_df = data_sales.groupby(['date_block_num'],as_index=False).agg({'target':'mean'}).rename(columns={'target':'target_mean_month'})\n",
    "data_sales = pd.merge(data_sales, agg_df, how='left', on=['date_block_num'])\n",
    "\n",
    "lags = [1, 2, 3, 6, 12]\n",
    "group_cols = ['shop_id', 'item_id']\n",
    "shift_col = 'target_mean_month'\n",
    "order_col = 'date_block_num' \n",
    "\n",
    "\n",
    "data_sales = lag_feature(data_sales, lags,shift_col)\n",
    "data_sales.drop(columns = ['target_mean_month'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Lagging targets mean shop-month\n",
    "agg_df = data_sales.groupby(['shop_id', 'date_block_num'],as_index=False).agg({'target':'mean'}).rename(columns={'target':'target_shop_mean'})\n",
    "data_sales = pd.merge(data_sales, agg_df, how='left', on=['shop_id', 'date_block_num'])\n",
    "lags = [1, 2, 3, 12]\n",
    "group_cols = ['shop_id', 'item_id']\n",
    "shift_col = 'target_shop_mean'\n",
    "order_col = 'date_block_num' \n",
    "\n",
    "data_sales = lag_feature(data_sales, lags, shift_col)\n",
    "data_sales.drop(columns = ['target_shop_mean'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# The same as above but with category-month mean\n",
    "agg_df = data_sales.groupby(['item_category_id', 'date_block_num'],as_index=False).agg({'target':'mean'}).rename(columns={'target':'target_category_mean'})\n",
    "data_sales = pd.merge(data_sales, agg_df, how='left', on=['item_category_id', 'date_block_num'])\n",
    "\n",
    "lags = [1, 2, 3, 12]\n",
    "group_cols = ['shop_id', 'item_id']\n",
    "shift_col = 'target_category_mean'\n",
    "order_col = 'date_block_num' \n",
    "\n",
    "\n",
    "data_sales = lag_feature(data_sales, lags,shift_col)\n",
    "data_sales.drop(columns = ['target_category_mean'], axis = 1, inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Same as above but with item-month aggregates\n",
    "agg_df = data_sales.groupby(['item_id', 'date_block_num'],as_index=False).agg({'target':'mean'}).rename(columns={'target':'target_item_mean'})\n",
    "data_sales = pd.merge(data_sales, agg_df, how='left', on=['item_id', 'date_block_num'])\n",
    "\n",
    "lags = [1,2,3]\n",
    "group_cols = ['shop_id', 'item_id']\n",
    "shift_col = 'target_item_mean'\n",
    "order_col = 'date_block_num' \n",
    "\n",
    "data_sales = lag_feature(data_sales, lags,shift_col)\n",
    "\n",
    "data_sales.drop(columns = ['target_item_mean'], axis = 1, inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Downcast dtypes from 64 to 32 bit to save memory\n",
    "data_sales = downcast_dtypes(data_sales)\n",
    "del grid, agg_df\n",
    "gc.collect();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Same as above but with city-month aggregates\n",
    "agg_df = data_sales.groupby(['city', 'date_block_num'],as_index=False).agg({'target':'mean'}).rename(columns={'target':'target_city_mean'})\n",
    "data_sales = pd.merge(data_sales, agg_df, how='left', on=['city', 'date_block_num'])\n",
    "\n",
    "lags = [1,2]\n",
    "group_cols = ['shop_id', 'item_id']\n",
    "shift_col = 'target_city_mean'\n",
    "order_col = 'date_block_num' \n",
    "\n",
    "data_sales = lag_feature(data_sales, lags,shift_col)\n",
    "data_sales.drop(columns = ['target_city_mean'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Same as above but with type-month aggregates\n",
    "agg_df = data_sales.groupby(['type', 'date_block_num'],as_index=False).agg({'target':'mean'}).rename(columns={'target':'target_type_mean'})\n",
    "data_sales = pd.merge(data_sales, agg_df, how='left', on=['type', 'date_block_num'])\n",
    "\n",
    "lags = [1]\n",
    "group_cols = ['shop_id', 'item_id']\n",
    "shift_col = 'target_type_mean'\n",
    "order_col = 'date_block_num' \n",
    "\n",
    "data_sales = lag_feature(data_sales, lags,shift_col)\n",
    "data_sales.drop(columns = ['target_type_mean'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Downcast dtypes from 64 to 32 bit to save memory\n",
    "data_sales = downcast_dtypes(data_sales)\n",
    "del agg_df\n",
    "gc.collect();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add price feature of each item, for each month and average for all months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "price_item = df_sales.loc[(df_sales.date_block_num!=34),:].groupby(['item_id']).agg({'item_price': ['mean']})\n",
    "price_item.columns = ['mean_item_price']\n",
    "price_item.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Add average item price for item id, month tuple\n",
    "price_item_month = df_sales.loc[(df_sales.date_block_num!=34),:].groupby(['date_block_num','item_id']).agg({'item_price': ['mean']})\n",
    "price_item_month.columns = ['mean_item_price_month']\n",
    "price_item_month.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_sales[['mean_item_price']] = pd.merge(data_sales[['item_id']], price_item, on=['item_id'], how='left')[['mean_item_price']]\n",
    "data_sales[['mean_item_price_month']] = pd.merge(data_sales[['item_id', 'date_block_num']], price_item_month, on=['item_id', 'date_block_num'], how='left')[['mean_item_price_month']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del df_sales\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encode number of days and weekends in each month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "year = 2013\n",
    "month = 1\n",
    "day = 1\n",
    "weekends_num = []\n",
    "for i in range(40):\n",
    "    \n",
    "    # Start date is the current date\n",
    "    day_start, month_start, year_start = day, month, year\n",
    "    \n",
    "    # Calculate the end date: the same day in the next month\n",
    "    day_end = day_start\n",
    "    month_end = month%12 + 1\n",
    "    year_end = year_start if month_start != 12 else year_start+1\n",
    "    \n",
    "    start = f\"{year_start}/{month_start}/{day_start}\"\n",
    "    end = f\"{year_end}/{month_end}/{day_end}\"\n",
    "    \n",
    "    weekends = pd.bdate_range(start=start, end=end, freq=\"C\", weekmask=\"Sat Sun\").shape[0]\n",
    "    weekends_num.append(weekends)\n",
    "    \n",
    "    month = month%12 + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Addeding month, number of days and number of weekends in each month\n",
    "data_sales['month'] = data_sales['date_block_num'] % 12\n",
    "\n",
    "day_nums = pd.Series([31,28,31,30,31,30,31,31,30,31,30,31])\n",
    "data_sales['days'] = data_sales['month'].map(day_nums).astype(np.int8)\n",
    "\n",
    "data_sales['weekends'] = data_sales['month'].map(lambda x: weekends_num[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_sales = downcast_dtypes(data_sales)\n",
    "gc.collect();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lags = [1,2,3,4,5,6]\n",
    "group_cols = ['shop_id', 'item_id']\n",
    "shift_col = \"mean_item_price_month\"\n",
    "order_col = 'date_block_num' \n",
    "\n",
    "data_sales = lag_feature(data_sales, lags,shift_col)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in [1,2,3,4,5,6]:\n",
    "    data_sales[\"price_fluct_lag_\" + str(i) ] = (data_sales[\"mean_item_price_month_lag_\" + str(i)] - data_sales[\"mean_item_price\"] ) / data_sales[\"mean_item_price\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_sales.drop(columns=['mean_item_price_month'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save it to the disk, and reset the notebook and get rid of the variables in memory to escape potential memory bottlenecks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_sales = downcast_dtypes(data_sales)\n",
    "gc.collect()\n",
    "data_sales.to_pickle('data/data_sales_00.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%reset -f\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "\n",
    "\n",
    "pd.set_option('display.max_rows', 600)\n",
    "pd.set_option('display.max_columns', 50)\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def price_fluctuation_last(row):\n",
    "    '''\n",
    "    Returns the last price fluctuation\n",
    "    If there is no fluctutation, then it returns 0\n",
    "    '''\n",
    "    for i in shift_range:\n",
    "        if row[\"price_fluct_lag_\" + str(i)]:\n",
    "            return row[\"price_fluct_lag_\" + str(i)]\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_sales = pd.read_pickle('data/data_sales_00.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "shift_range = [1, 2, 3, 4, 5, 6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the last price nonzero price fluctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_sales[\"price_fluct_lag\"] = data_sales.apply(price_fluctuation_last, axis = 1)\n",
    "data_sales[\"price_fluct_lag\"] = data_sales.price_fluct_lag.astype( np.float16 )\n",
    "data_sales[\"price_fluct_lag\"].fillna(0 ,inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['price_fluct_lag_1',\n",
       " 'price_fluct_lag_2',\n",
       " 'price_fluct_lag_3',\n",
       " 'price_fluct_lag_4',\n",
       " 'price_fluct_lag_5',\n",
       " 'price_fluct_lag_6']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We will drop these at fitting stage\n",
    "to_drop_cols = []\n",
    "\n",
    "for i in shift_range:\n",
    "    to_drop_cols.append(\"price_fluct_lag_\" + str(i) )\n",
    "to_drop_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['price_fluct_lag_1',\n",
       " 'price_fluct_lag_2',\n",
       " 'price_fluct_lag_3',\n",
       " 'price_fluct_lag_4',\n",
       " 'price_fluct_lag_5',\n",
       " 'price_fluct_lag_6',\n",
       " 'mean_item_price_month_lag_1',\n",
       " 'mean_item_price_month_lag_2',\n",
       " 'mean_item_price_month_lag_3',\n",
       " 'mean_item_price_month_lag_4',\n",
       " 'mean_item_price_month_lag_5',\n",
       " 'mean_item_price_month_lag_6']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in shift_range:\n",
    "    to_drop_cols.append(\"mean_item_price_month_lag_\" + str(i) )\n",
    "to_drop_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_sales.drop(columns=to_drop_cols, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_sales.drop(columns=['mean_item_price'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save it to the disk to avoid memory overload\n",
    "data_sales.to_pickle('data/data_sales_01.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
